from typing import Dict, List, Optional
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from .memory import ConversationMemory
from .visualizer import RequirementsVisualizer

@dataclass
class UnderstandingStatus:
    timestamp: datetime
    confidence: float
    key_points: List[str]
    interpretations: Dict[str, str]
    uncertain_areas: List[str]
    user_input: str
    ai_response: str

class UnderstandingTracker:
    def __init__(self, memory: ConversationMemory,  output_dir: str = "outputs"):
        self.output_dir = Path(output_dir)
        self.memory = memory
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.history: List[UnderstandingStatus] = []
        self.understanding_file = self._get_understanding_file()
        self.visualizer = RequirementsVisualizer()
        
    def update_requirements(self):
        """è¦ä»¶ä¸€è¦§ãŒå¤‰æ›´ã•ã‚ŒãŸéš›ã«å‘¼ã³å‡ºã™"""
        self._update_markdown()

    def _get_understanding_file(self) -> Path:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã®ç†è§£çŠ¶æ³ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ç”Ÿæˆ"""
        safe_name = "".join(c for c in self.memory.project_name if c.isalnum() or c in (' ', '-', '_')).strip()
        safe_name = safe_name.replace(' ', '_').lower() or "unnamed_project"
        return self.output_dir / f"understanding_{safe_name}.md"

    def add_status(self, status: UnderstandingStatus):
        """æ–°ã—ã„ç†è§£çŠ¶æ³ã‚’è¿½åŠ """
        self.history.append(status)
        self._update_markdown()
    
    def _update_markdown(self):
        """ç†è§£çŠ¶æ³ã®Markdownã‚’æ›´æ–°"""
        content = ["# RD-Assistantã®ç†è§£çŠ¶æ³\n"]
        content.append(f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        content.append("## ğŸ—º è¦ä»¶ã®å…¨ä½“åƒ")
        content.append("\nä»¥ä¸‹ã®ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—ã¯ã€ç¾åœ¨ã®è¦ä»¶ã®æ§‹é€ ã‚’è¡¨ã—ã¦ã„ã¾ã™ï¼š")
        content.append("\n```mermaid")
        content.append(self.visualizer.generate_mindmap(self.memory))
        content.append("```\n")

        content.append("## ğŸ”„ è¦ä»¶ã®é–¢ä¿‚æ€§")
        content.append("\nä»¥ä¸‹ã®å›³ã¯ã€è¦ä»¶é–“ã®ä¾å­˜é–¢ä¿‚ã‚„é–¢é€£æ€§ã‚’ç¤ºã—ã¦ã„ã¾ã™ï¼š")
        content.append("\n```mermaid")
        content.append(self.visualizer.generate_flowchart(self.memory))
        content.append("```\n")

        if any(hasattr(req, 'metadata') and 'priority' in req.metadata for req in self.memory.requirements):
            content.append("## ğŸ“Š å„ªå…ˆé †ä½ãƒãƒƒãƒ—")
            content.append("\nä»¥ä¸‹ã®å›³ã¯ã€è¦ä»¶ã®å„ªå…ˆé †ä½ã¨ä¾å­˜é–¢ä¿‚ã‚’ç¤ºã—ã¦ã„ã¾ã™ï¼š")
            content.append("\n```mermaid")
            content.append(self._generate_priority_flowchart())
            content.append("```\n")

        content.append("## ğŸ“‹ ç¾åœ¨ã®è¦ä»¶ä¸€è¦§")
        
        requirements = self.memory.requirements
        grouped_reqs = {
            "functional": [],
            "non_functional": [],
            "technical": [],
            "business": []
        }
        
        for req in requirements:
            if req.type in grouped_reqs:
                grouped_reqs[req.type].append(req)
        
        type_names = {
            "functional": "ğŸ”§ æ©Ÿèƒ½è¦ä»¶",
            "non_functional": "âš™ï¸ éæ©Ÿèƒ½è¦ä»¶",
            "technical": "ğŸ’» æŠ€è¡“è¦ä»¶",
            "business": "ğŸ’¼ ãƒ“ã‚¸ãƒã‚¹è¦ä»¶"
        }
        
        for req_type, reqs in grouped_reqs.items():
            if reqs:
                content.append(f"\n### {type_names[req_type]}")
                for req in reqs:
                    priority = req.metadata.get('priority', '')
                    priority_emoji = {
                        'must_have': 'ğŸ”´',
                        'should_have': 'ğŸŸ¡',
                        'could_have': 'ğŸŸ¢',
                        'won\'t_have': 'âšª'
                    }.get(priority, '')
                    
                    content.append(f"\n#### {priority_emoji} {req.content}")
                    if req.rationale:
                        content.append(f"ç†ç”±: {req.rationale}")
                    if 'review_score' in req.metadata:
                        score = req.metadata['review_score']
                        content.append(f"å“è³ªã‚¹ã‚³ã‚¢: {score:.2f}")
        
        content.append("\n---\n") 
        
        if self.history:
            latest = self.history[-1]
            content.append("## ç¾åœ¨ã®ç†è§£åº¦")
            confidence_bar = "â–ˆ" * int(latest.confidence * 20)
            content.append(f"[{confidence_bar:<20}] {latest.confidence*100:.1f}%\n")

            content.append("## æœ€æ–°ã®ç†è§£å†…å®¹")
            content.append("\n### æŠ½å‡ºã—ãŸã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ")
            for point in latest.key_points:
                content.append(f"- {point}")
            
            content.append("\n### è¦ä»¶ã¨ã—ã¦è§£é‡ˆã—ãŸå†…å®¹")
            for category, interpretation in latest.interpretations.items():
                content.append(f"#### {category}")
                content.append(interpretation)
            
            if latest.uncertain_areas:
                content.append("\n### ç¢ºèªãŒå¿…è¦ãªç‚¹")
                for area in latest.uncertain_areas:
                    content.append(f"- â“ {area}")
            
            content.append("\n## ğŸ“ å¯¾è©±å±¥æ­´")
            for status in reversed(self.history[-10:]):  # æœ€æ–°10ä»¶ã®ã¿è¡¨ç¤º
                content.append(f"\n### {status.timestamp.strftime('%H:%M:%S')}")
                content.append(f"**ãƒ¦ãƒ¼ã‚¶ãƒ¼**: {status.user_input}")
                content.append(f"\n**AI**: {status.ai_response}")
                content.append("\n---")

        with open(self.understanding_file, "w", encoding="utf-8") as f:
            f.write("\n".join(content))

    def _generate_priority_flowchart(self) -> str:
        """å„ªå…ˆé †ä½ã‚’è€ƒæ…®ã—ãŸãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        lines = ["graph TD"]
        
        colors = {
            "must_have": "#ff6b6b",     # èµ¤
            "should_have": "#ffd93d",   # é»„
            "could_have": "#6bff6b",    # ç·‘
            "wont_have": "#d3d3d3"     # ã‚°ãƒ¬ãƒ¼
        }
        
        # ãƒãƒ¼ãƒ‰ã®ç”Ÿæˆ
        for i, req in enumerate(self.memory.requirements):
            node_id = f"R{i}"
            priority = req.metadata.get('priority', 'undefined')
            color = colors.get(priority, "#d3d3d3")
            
            # ãƒãƒ¼ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
            lines.append(f"    {node_id}[{req.content}]")
            lines.append(f"    style {node_id} fill:{color}")
            
            # ä¾å­˜é–¢ä¿‚ã®è¨­å®š
            if 'dependencies' in req.metadata:
                for dep in req.metadata['dependencies']:
                    for j, other_req in enumerate(self.memory.requirements):
                        if other_req.content == dep:
                            lines.append(f"    R{j} --> {node_id}")
        
        # å‡¡ä¾‹ã®è¿½åŠ 
        lines.append("    subgraph å„ªå…ˆåº¦")
        lines.append("    L1[Must Have]")
        lines.append("    L2[Should Have]")
        lines.append("    L3[Could Have]")
        lines.append('    L4["Won\'t Have"]')
        lines.append("    end")
        
        # å‡¡ä¾‹ã®ã‚¹ã‚¿ã‚¤ãƒ«
        lines.append(f"    style L1 fill:{colors['must_have']}")
        lines.append(f"    style L2 fill:{colors['should_have']}")
        lines.append(f"    style L3 fill:{colors['could_have']}")
        lines.append(f"    style L4 fill:{colors['wont_have']}")
        
        return "\n".join(lines)