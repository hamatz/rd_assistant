from typing import List, Dict, Optional
from dataclasses import dataclass, field
from datetime import datetime
import re
from .memory import ConversationMemory, Requirement

@dataclass
class ReviewComment:
    role: str
    category: str
    content: str
    importance: str  # high, medium, low
    suggestion: str

@dataclass
class ReviewResult:
    comments: List[ReviewComment]
    overall_evaluation: str
    improvement_suggestions: List[Dict]
    discussion_summary: str
    discussion: List[Dict] = field(default_factory=list)

@dataclass
class DocumentChunk:
    content: str
    section_type: str
    section_name: str
    requirements_count: int

class DocumentProcessor:
    """è¦ä»¶å®šç¾©æ›¸ã®åˆ†å‰²ã¨å‡¦ç†ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, llm_config: 'LLMConfig'):
        # ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®25%ã‚’ãƒ¬ã‚¹ãƒãƒ³ã‚¹ç”¨ã«ç¢ºä¿
        self.max_chunk_size = int(llm_config.max_tokens * 0.75)

    async def process_document(self, document: str) -> List[DocumentChunk]:
        """æ–‡æ›¸ã‚’å¿…è¦ã«å¿œã˜ã¦åˆ†å‰²"""
        estimated_tokens = self.estimate_tokens(document)
        print(f"\nğŸ“Š æ¨å®šãƒˆãƒ¼ã‚¯ãƒ³æ•°: {estimated_tokens}")
        
        if estimated_tokens <= self.max_chunk_size:
            print("\nğŸ” æ–‡æ›¸ã‚’ä¸€æ‹¬ã§å‡¦ç†ã—ã¾ã™...")
            return [DocumentChunk(
                content=document,
                section_type="complete",
                section_name="å®Œå…¨ãªæ–‡æ›¸",
                requirements_count=document.count('###')
            )]
        
        print(f"\nğŸ”„ æ–‡æ›¸ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™...")
        print(f"   æœ€å¤§ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {self.max_chunk_size}")
        return self._split_document(document)

    def _split_document(self, document: str) -> List[DocumentChunk]:
        """è¦ä»¶å®šç¾©æ›¸ã‚’é©åˆ‡ãªã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        chunks = []
        current_section = ""
        current_content = []
        current_size = 0
        requirements_count = 0

        lines = document.split('\n')
        for line in lines:
            if line.startswith('# '):
                if current_content:
                    chunks.append(self._create_chunk(current_section, current_content, requirements_count))
                current_section = line
                current_content = [line]
                current_size = len(line)
                requirements_count = 0
            elif line.startswith('## '):
                if current_size > self.max_chunk_size:
                    chunks.append(self._create_chunk(current_section, current_content, requirements_count))
                    current_content = []
                    current_size = 0
                    requirements_count = 0
                current_section = line
                current_content.append(line)
                current_size += len(line)
            else:
                if '###' in line:
                    requirements_count += 1
                
                current_content.append(line)
                current_size += len(line)
                
                # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã®åˆ¶é™ã‚’è¶…ãˆãŸå ´åˆ
                if current_size > self.max_chunk_size:
                    chunks.append(self._create_chunk(current_section, current_content, requirements_count))
                    current_content = []
                    current_size = 0
                    requirements_count = 0

        if current_content:
            chunks.append(self._create_chunk(current_section, current_content, requirements_count))

        return chunks

    def _create_chunk(self, section: str, content: List[str], req_count: int) -> DocumentChunk:
        """ãƒãƒ£ãƒ³ã‚¯ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ"""
        section_type = "header" if section.startswith("# ") else "section"
        section_name = section.strip("# ").strip()
        return DocumentChunk(
            content="\n".join(content),
            section_type=section_type,
            section_name=section_name,
            requirements_count=req_count
        )

    def estimate_tokens(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¦‚ç®—"""
        # æ–‡å­—æ•°ã‚’ãƒ™ãƒ¼ã‚¹ã«ã—ãŸç°¡æ˜“çš„ãªæ¨å®š
        # è‹±èªã¯å¹³å‡4æ–‡å­—/ãƒˆãƒ¼ã‚¯ãƒ³ã€æ—¥æœ¬èªã¯2æ–‡å­—/ãƒˆãƒ¼ã‚¯ãƒ³ç¨‹åº¦ã¨ã—ã¦è¨ˆç®—
        jp_char_count = len(re.findall(r'[\u3000-\u303f\u3040-\u309f\u30a0-\u30ff\u4e00-\u9faf]', text))
        en_char_count = len(text) - jp_char_count
        
        return (jp_char_count // 2) + (en_char_count // 4)

class ReviewManager:
    """ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ã‚»ã‚¹ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, llm_service, max_tokens: int = 4000):
        self.llm_service = llm_service
        self.max_tokens = max_tokens
        self.document_processor = DocumentProcessor(self.llm_service.config)

    async def process_document(self, document: str, memory: ConversationMemory) -> ReviewResult:
        """æ–‡æ›¸ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã—ã€çµæœã‚’çµ±åˆ"""
        chunks = self.document_processor.split_document(document)
        
        chunk_reviews = []
        
        print(f"\nğŸ“„ æ–‡æ›¸ã‚’ {len(chunks)} å€‹ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«åˆ†å‰²ã—ã¦å‡¦ç†ã—ã¾ã™...")
        
        for i, chunk in enumerate(chunks, 1):
            print(f"\nğŸ” ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i}/{len(chunks)} ã‚’å‡¦ç†ä¸­: {chunk.section_name}")
            print(f"   è¦ä»¶æ•°: {chunk.requirements_count}")
            
            review = await self._review_chunk(chunk, memory)
            chunk_reviews.append(review)
        
        return self._merge_reviews(chunk_reviews)

    async def _review_chunk(self, chunk: DocumentChunk, memory: ConversationMemory) -> Dict:
        """å€‹åˆ¥ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
        prompt = self._create_review_prompt(chunk, memory)
        
        try:
            response = await self.llm_service.generate_response(prompt)
            print(f"âœ… {chunk.section_name} ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†")
            return response
        except Exception as e:
            print(f"âš ï¸ {chunk.section_name} ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._create_empty_review()

    def _create_review_prompt(self, chunk: DocumentChunk, memory: ConversationMemory) -> str:
        """ãƒãƒ£ãƒ³ã‚¯ç”¨ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        return f"""
ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®è¦ä»¶å®šç¾©æ›¸ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦:
{memory.project_description}

ã‚»ã‚¯ã‚·ãƒ§ãƒ³: {chunk.section_name}
å†…å®¹:
{chunk.content}

ä»¥ä¸‹ã®å½¢å¼ã§JSONã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "comments": [
        {{
            "category": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒª",
            "content": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆ",
            "importance": "high|medium|low",
            "suggestion": "æ”¹å–„ææ¡ˆ"
        }}
    ]
}}
"""

    def _create_empty_review(self) -> Dict:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ç©ºã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’ç”Ÿæˆ"""
        return {
            "comments": [],
            "section_status": "error"
        }

    def _merge_reviews(self, reviews: List[Dict]) -> ReviewResult:
        """è¤‡æ•°ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆ"""
        all_comments = []
        for review in reviews:
            for comment_data in review.get("comments", []):
                try:
                    comment = ReviewComment(
                        role="çµ±åˆãƒ¬ãƒ“ãƒ¥ãƒ¼",
                        category=comment_data["category"],
                        content=comment_data["content"],
                        importance=comment_data["importance"],
                        suggestion=comment_data["suggestion"]
                    )
                    all_comments.append(comment)
                except KeyError:
                    continue
        
        unique_comments = self._deduplicate_comments(all_comments)
        
        return ReviewResult(
            comments=unique_comments,
            overall_evaluation=self._generate_overall_evaluation(reviews),
            improvement_suggestions=self._merge_suggestions(reviews),
            discussion_summary=self._generate_merged_summary(reviews)
        )

    def _deduplicate_comments(self, comments: List[ReviewComment]) -> List[ReviewComment]:
        """é‡è¤‡ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆã‚’æ’é™¤"""
        seen = set()
        unique = []
        
        for comment in comments:
            key = (comment.content, comment.category)
            if key not in seen:
                seen.add(key)
                unique.append(comment)
        
        importance_order = {"high": 0, "medium": 1, "low": 2}
        return sorted(unique, key=lambda x: importance_order[x.importance])

    def _generate_overall_evaluation(self, reviews: List[Dict]) -> str:
        """å…¨ä½“è©•ä¾¡ã‚’ç”Ÿæˆ"""
        return "å…¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†ã—ã¾ã—ãŸã€‚"

    def _merge_suggestions(self, reviews: List[Dict]) -> List[Dict]:
        """æ”¹å–„ææ¡ˆã‚’çµ±åˆ"""
        all_suggestions = []
        for review in reviews:
            if "suggestions" in review:
                all_suggestions.extend(review["suggestions"])
        
        seen = set()
        unique_suggestions = []
        for suggestion in all_suggestions:
            key = (suggestion.get("area", ""), suggestion.get("suggestion", ""))
            if key not in seen:
                seen.add(key)
                unique_suggestions.append(suggestion)
        
        return unique_suggestions

    def _generate_merged_summary(self, reviews: List[Dict]) -> str:
        """çµ±åˆã•ã‚ŒãŸè¦ç´„ã‚’ç”Ÿæˆ"""
        return "å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœã‚’çµ±åˆã—ã¾ã—ãŸã€‚"

class RequirementsReviewer:
    def __init__(self, llm_service):
        self.llm_service = llm_service
        self.review_manager = ReviewManager(llm_service)
        self.reviewer_roles = [
            {
                "role": "æŠ€è¡“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ",
                "focus": "æŠ€è¡“çš„ãªå®Ÿç¾å¯èƒ½æ€§ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ã€ä¿å®ˆæ€§"
            },
            {
                "role": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å°‚é–€å®¶",
                "focus": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã€ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã€ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹"
            },
            {
                "role": "ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼",
                "focus": "ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ã€ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æº€è¶³åº¦"
            },
            {
                "role": "ãƒ“ã‚¸ãƒã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆ",
                "focus": "ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤ã€å¸‚å ´é©åˆæ€§ã€ROI"
            },
            {
                "role": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼",
                "focus": "å®Ÿç¾å¯èƒ½æ€§ã€ãƒªã‚½ãƒ¼ã‚¹è¦ä»¶ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"
            }
        ]

    async def review_requirements(self, memory: ConversationMemory, document: str) -> ReviewResult:
        """è¦ä»¶å®šç¾©æ›¸ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ"""
        try:
            chunks = await self.review_manager.document_processor.process_document(document)
            
            if len(chunks) == 1:
                return await self._perform_single_review(document, memory)
            else:
                return await self._perform_chunked_review(chunks, memory)
                
        except Exception as e:
            print(f"\nâŒ ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            raise

    async def _generate_discussion(self, reviews: List[ReviewComment], document: str) -> Dict:
        """å°‚é–€å®¶é–“ã®è¨è«–ã‚’ç”Ÿæˆ"""
        print("\nğŸ’­ å°‚é–€å®¶é–“ã®è¨è«–ã‚’ç”Ÿæˆä¸­...")
        
        reviews_text = "\n".join([
            f"{review.role}ã®ã‚³ãƒ¡ãƒ³ãƒˆ:\n"
            f"- åˆ†é¡: {review.category}\n"
            f"- å†…å®¹: {review.content}\n"
            f"- ææ¡ˆ: {review.suggestion}\n"
            for review in reviews
        ])

        prompt = f"""
    ä»¥ä¸‹ã®è¦ä»¶å®šç¾©æ›¸ã«å¯¾ã™ã‚‹å„å°‚é–€å®¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åŸºã«ã€å»ºè¨­çš„ãªè¨è«–ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
    ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰ã®æ„è¦‹ã‚’è€ƒæ…®ã—ã€ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè©•ä¾¡ã¨æ”¹å–„ã®æ–¹å‘æ€§ã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚

    ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆ:
    {reviews_text}

    è¦ä»¶å®šç¾©æ›¸:
    {document}

    ä»¥ä¸‹ã®å½¢å¼ã§JSONã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
    {{
        "discussion": [
            {{
                "speaker": "å°‚é–€å®¶ã®å½¹å‰²",
                "point": "è­°è«–ã®ãƒã‚¤ãƒ³ãƒˆ",
                "response_to": "ä»–ã®å°‚é–€å®¶ã®æŒ‡æ‘˜ã¸ã®å¿œç­”ï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰"
            }}
        ],
        "summary": "è¨è«–ã®è¦ç´„ã¨ä¸»è¦ãªåˆæ„ç‚¹",
        "evaluation": "è¦ä»¶å®šç¾©æ›¸ã®ç·åˆè©•ä¾¡"
    }}
    """
        try:
            response = await self.llm_service.generate_response(prompt)
            print("âœ… è¨è«–ã®ç”ŸæˆãŒå®Œäº†")
            return response
        except Exception as e:
            print(f"âŒ è¨è«–ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                "discussion": [],
                "summary": "è¨è«–ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
                "evaluation": "è©•ä¾¡ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸ"
            }
        
    async def _generate_improvements(self, reviews: List[ReviewComment], discussion: Dict) -> Dict:
        """æœ€çµ‚çš„ãªæ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ"""
        print("\nğŸ’¡ æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆä¸­...")
        
        reviews_text = "\n".join([
            f"- {review.role}: {review.content} (é‡è¦åº¦: {review.importance})"
            for review in reviews
        ])

        prompt = f"""
    ä»¥ä¸‹ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨è¨è«–ã®çµæœã‚’åŸºã«ã€å…·ä½“çš„ãªæ”¹å–„ææ¡ˆã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
    ææ¡ˆã¯å®Ÿè¡Œå¯èƒ½ã§ã€å„ªå…ˆé †ä½ãŒæ˜ç¢ºãªã‚‚ã®ã«ã—ã¦ãã ã•ã„ã€‚

    ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆ:
    {reviews_text}

    è¨è«–ã‚µãƒãƒªãƒ¼:
    {discussion.get('summary', 'è¨è«–æƒ…å ±ãªã—')}

    ä»¥ä¸‹ã®å½¢å¼ã§JSONã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
    {{
        "suggestions": [
            {{
                "priority": "high|medium|low",
                "area": "æ”¹å–„é ˜åŸŸ",
                "suggestion": "å…·ä½“çš„ãªæ”¹å–„ææ¡ˆ",
                "rationale": "ææ¡ˆã®ç†ç”±"
            }}
        ]
    }}
    """
        try:
            response = await self.llm_service.generate_response(prompt)
            print("âœ… æ”¹å–„ææ¡ˆã®ç”ŸæˆãŒå®Œäº†")
            return response
        except Exception as e:
            print(f"âŒ æ”¹å–„ææ¡ˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {"suggestions": []}     

    async def _perform_single_review(self, document: str, memory: ConversationMemory) -> ReviewResult:
        """æ–‡æ›¸ãŒå°ã•ã„å ´åˆã®å˜ä¸€ãƒ¬ãƒ“ãƒ¥ãƒ¼å‡¦ç†"""
        reviews = []
        for role in self.reviewer_roles:
            review = await self._get_expert_review(role, document, memory)
            reviews.extend(review)

        discussion = await self._generate_discussion(reviews, document)

        improvements = await self._generate_improvements(reviews, discussion)

        return ReviewResult(
            comments=reviews,
            overall_evaluation=discussion.get("evaluation", "è©•ä¾¡ã‚’å®Œäº†ã§ãã¾ã›ã‚“ã§ã—ãŸ"),
            improvement_suggestions=improvements.get("suggestions", []),
            discussion_summary=discussion.get("summary", "è¨è«–ã®ã¾ã¨ã‚ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸ"),
            discussion=discussion.get("discussion", [])
        )

    async def _perform_chunked_review(self, chunks: List[DocumentChunk], memory: ConversationMemory) -> ReviewResult:
        """åˆ†å‰²ã•ã‚ŒãŸæ–‡æ›¸ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œ"""
        chunk_reviews = []
        
        for i, chunk in enumerate(chunks, 1):
            print(f"\nğŸ“„ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ {i}/{len(chunks)} ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­: {chunk.section_name}")
            review = await self._perform_single_review(chunk.content, memory)
            chunk_reviews.append(review)
        
        return self._merge_review_results(chunk_reviews)

    async def _get_expert_review(self, role: Dict, document: str, memory: ConversationMemory) -> List[ReviewComment]:
        """å„å°‚é–€å®¶ã®å½¹å‰²ã§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—"""
        print(f"\nğŸ‘¤ {role['role']}ã¨ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å®Ÿè¡Œä¸­...")
        
        vision_context = ""
        if memory.project_vision:
            vision = memory.project_vision
            vision_context = f"""
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ“ã‚¸ãƒ§ãƒ³ï¼š
    - ç›®æ¨™: {', '.join(vision.goals)}
    - æˆåŠŸåŸºæº–: {', '.join(vision.success_criteria)}
    - å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼: {', '.join(vision.target_users)}
    """
        
        prompt = f"""
    ã‚ãªãŸã¯{role['role']}ã¨ã—ã¦ã€ä»¥ä¸‹ã®è¦ä»¶å®šç¾©æ›¸ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚
    ç‰¹ã« {role['focus']} ã®è¦³ç‚¹ã‹ã‚‰è©•ä¾¡ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

    {vision_context}
    ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦:
    {memory.project_description}

    è¦ä»¶å®šç¾©æ›¸:
    {document}

    ä»¥ä¸‹ã®ç‚¹ã‚’è€ƒæ…®ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’è¡Œã£ã¦ãã ã•ã„ï¼š
    1. è¦ä»¶ãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç›®æ¨™ã‚„æˆåŠŸåŸºæº–ã¨æ•´åˆã—ã¦ã„ã‚‹ã‹
    2. å¯¾è±¡ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‹ãƒ¼ã‚ºã‚’é©åˆ‡ã«æº€ãŸã—ã¦ã„ã‚‹ã‹
    3. è¨­å®šã•ã‚ŒãŸå„ªå…ˆé †ä½ãŒå¦¥å½“ã‹
    4. ã‚ãªãŸã®å°‚é–€åˆ†é‡ã‹ã‚‰ã¿ãŸèª²é¡Œã‚„æ”¹å–„ç‚¹

    ä»¥ä¸‹ã®å½¢å¼ã§JSONã¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ï¼š
    {{
        "comments": [
            {{
                "category": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚«ãƒ†ã‚´ãƒª",
                "content": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ¡ãƒ³ãƒˆ",
                "importance": "high|medium|low",
                "suggestion": "æ”¹å–„ææ¡ˆ"
            }}
        ]
    }}
    """
        try:
            response = await self.llm_service.generate_response(prompt)
            print(f"âœ… {role['role']}ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®Œäº†")
            
            comments = []
            for comment_data in response.get("comments", []):
                try:
                    comment = ReviewComment(
                        role=role["role"],
                        category=comment_data["category"],
                        content=comment_data["content"],
                        importance=comment_data["importance"],
                        suggestion=comment_data["suggestion"]
                    )
                    comments.append(comment)
                except KeyError as e:
                    print(f"âš ï¸ ã‚³ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            
            return comments
            
        except Exception as e:
            print(f"âŒ {role['role']}ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸­ã«ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []